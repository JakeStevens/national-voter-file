# NVF with Docker

This directory contains docker resources to bring up a local national voter file.

We use [docker-compose](https://docs.docker.com/compose/) to manage interactions between the containers. This is already installed with Docker if you are using Windows or Mac.

## Getting started:

1. Move to the docker directory: `cd docker`
2. Build the docker containers: `docker-compose build`
3. Launch the warehouse with the command `docker-compose up`

4. Use your favorite (postgres-supporting) SQLing tool to connect (just fill in the ones your tool requires):

   * URL: `jdbc:postgresql://postgis:5432/VOTER`
   * Driver: `org.postgresql.Driver`
   * Host: `localhost`
   * Port: `5432`
   * Database: `VOTER`
   * User: `postgres`
   * Password: blank

Note: The host should be `postgis` when accessed from inside the ETL docker container.

## Extracting, transforming, and loading (ETL)

This container is intended to run [Pentaho Data Integration](http://community.pentaho.com/projects/data-integration/) transforms and python scripts with some handy modules. These scripts and transforms are how we enrich, clean, and load data into the postgres database.

Typically, you will invoke commands in this container as

`docker-compose run etl`

## Running ETL Scripts

We've provided a shell script for loading in a 1,000 row sample of Washington state data. Take a look at buildWashington.sh for setting up a simple warehouse, or as guidance for running your own ETL jobs. It assumes that the voter file can be found in the data directory of this repo
(which is in .gitignore so you have to construct your own local version)

Copy those files into data/Washington directory of the national-voter-file repo

You can get samples of this data in our [private Dropbox](https://www.dropbox.com/work/getmovement%20Team%20Folder). Message us on Slack to get access.

### Loading Test Data

If you'd like to load test data for Washington state (generated by [Mockaroo](https://www.mockaroo.com/52c28de0)),
run the `buildTestData.sh` script while the container is running (either in the background
with detached mode `-d` or in a separate window).

### populateDateDimension.ktr
This transform creates records in the date dimension that has a row for every single date going out twenty years. This is required before loading any records into the warehouse.

### saveWashingtonPrecincts.ktr
This transform joins the Washington State precinct file with IDs from [Open Civic Data API](https://opencivicdata.readthedocs.io/en/latest/ocdids.html). This data is required before the voter file itself is loaded.


### ProcessWashingtonFile.kjb
This job glues together the steps required to load an entire voter file. For efficiency purposes, we run through the file once to extract any new households. We do it again to find new voter names.

Only after we perform this bulk load of households and voters do we go back and load all of the voter records which involves a lookup of this dimensional data.
